{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very simple and easy to apply chatbot that I built when I first join the working society in year 2018.\n",
    "# This is just for personal reference or future job application reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/695_1639_bundle_archive/human_text.txt', 'r', encoding='utf-8') as file:\n",
    "    human = file.read().split('\\n')\n",
    "with open('../input/695_1639_bundle_archive/robot_text.txt', 'r', encoding='utf-8') as file2:\n",
    "    robot = file2.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in human[:300]]\n",
    "human = [\" \".join(re.findall(r\"\\w+\",line)) for line in human]\n",
    "robot = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in robot[:300]]\n",
    "robot = [\" \".join(re.findall(r\"\\w+\",line)) for line in robot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for easier processing\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'human': human,\n",
    "             'robot': robot,\n",
    "             'pairs': list(zip(human, robot))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the data\n",
    "from nltk.tokenize import word_tokenize\n",
    "df['tokenized_human'] = df.human.apply(word_tokenize)\n",
    "df['tokenized_robot'] = df.robot.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>robot</th>\n",
       "      <th>pairs</th>\n",
       "      <th>tokenized_human</th>\n",
       "      <th>tokenized_robot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>hi there how are you</td>\n",
       "      <td>(hi, hi there how are you)</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>[hi, there, how, are, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oh thanks i m fine this is an evening in my ti...</td>\n",
       "      <td>here is afternoon</td>\n",
       "      <td>(oh thanks i m fine this is an evening in my t...</td>\n",
       "      <td>[oh, thanks, i, m, fine, this, is, an, evening...</td>\n",
       "      <td>[here, is, afternoon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do you feel today tell me something about ...</td>\n",
       "      <td>my name is rdany but you can call me dany the ...</td>\n",
       "      <td>(how do you feel today tell me something about...</td>\n",
       "      <td>[how, do, you, feel, today, tell, me, somethin...</td>\n",
       "      <td>[my, name, is, rdany, but, you, can, call, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many virtual friends have you got</td>\n",
       "      <td>i have many but not enough to fully understand...</td>\n",
       "      <td>(how many virtual friends have you got, i have...</td>\n",
       "      <td>[how, many, virtual, friends, have, you, got]</td>\n",
       "      <td>[i, have, many, but, not, enough, to, fully, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is that forbidden for you to tell the exact nu...</td>\n",
       "      <td>i ve talked with 143 users counting 7294 lines...</td>\n",
       "      <td>(is that forbidden for you to tell the exact n...</td>\n",
       "      <td>[is, that, forbidden, for, you, to, tell, the,...</td>\n",
       "      <td>[i, ve, talked, with, 143, users, counting, 72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>hello how s going</td>\n",
       "      <td>hi how are you</td>\n",
       "      <td>(hello how s going, hi how are you)</td>\n",
       "      <td>[hello, how, s, going]</td>\n",
       "      <td>[hi, how, are, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>i m fine and you</td>\n",
       "      <td>everything is fine on this side</td>\n",
       "      <td>(i m fine and you, everything is fine on this ...</td>\n",
       "      <td>[i, m, fine, and, you]</td>\n",
       "      <td>[everything, is, fine, on, this, side]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>we have a big snow outside</td>\n",
       "      <td>the kind that could make you stay home</td>\n",
       "      <td>(we have a big snow outside, the kind that cou...</td>\n",
       "      <td>[we, have, a, big, snow, outside]</td>\n",
       "      <td>[the, kind, that, could, make, you, stay, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>it may but i have to go for a long way</td>\n",
       "      <td>put on warm clothes</td>\n",
       "      <td>(it may but i have to go for a long way, put o...</td>\n",
       "      <td>[it, may, but, i, have, to, go, for, a, long, ...</td>\n",
       "      <td>[put, on, warm, clothes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>i m a bit affraid of bad roads cause i m going...</td>\n",
       "      <td>i think webhooks are more effective since it a...</td>\n",
       "      <td>(i m a bit affraid of bad roads cause i m goin...</td>\n",
       "      <td>[i, m, a, bit, affraid, of, bad, roads, cause,...</td>\n",
       "      <td>[i, think, webhooks, are, more, effective, sin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 human  \\\n",
       "0                                                   hi   \n",
       "1    oh thanks i m fine this is an evening in my ti...   \n",
       "2    how do you feel today tell me something about ...   \n",
       "3                how many virtual friends have you got   \n",
       "4    is that forbidden for you to tell the exact nu...   \n",
       "..                                                 ...   \n",
       "295                                  hello how s going   \n",
       "296                                   i m fine and you   \n",
       "297                         we have a big snow outside   \n",
       "298             it may but i have to go for a long way   \n",
       "299  i m a bit affraid of bad roads cause i m going...   \n",
       "\n",
       "                                                 robot  \\\n",
       "0                                 hi there how are you   \n",
       "1                                    here is afternoon   \n",
       "2    my name is rdany but you can call me dany the ...   \n",
       "3    i have many but not enough to fully understand...   \n",
       "4    i ve talked with 143 users counting 7294 lines...   \n",
       "..                                                 ...   \n",
       "295                                     hi how are you   \n",
       "296                    everything is fine on this side   \n",
       "297             the kind that could make you stay home   \n",
       "298                                put on warm clothes   \n",
       "299  i think webhooks are more effective since it a...   \n",
       "\n",
       "                                                 pairs  \\\n",
       "0                           (hi, hi there how are you)   \n",
       "1    (oh thanks i m fine this is an evening in my t...   \n",
       "2    (how do you feel today tell me something about...   \n",
       "3    (how many virtual friends have you got, i have...   \n",
       "4    (is that forbidden for you to tell the exact n...   \n",
       "..                                                 ...   \n",
       "295                (hello how s going, hi how are you)   \n",
       "296  (i m fine and you, everything is fine on this ...   \n",
       "297  (we have a big snow outside, the kind that cou...   \n",
       "298  (it may but i have to go for a long way, put o...   \n",
       "299  (i m a bit affraid of bad roads cause i m goin...   \n",
       "\n",
       "                                       tokenized_human  \\\n",
       "0                                                 [hi]   \n",
       "1    [oh, thanks, i, m, fine, this, is, an, evening...   \n",
       "2    [how, do, you, feel, today, tell, me, somethin...   \n",
       "3        [how, many, virtual, friends, have, you, got]   \n",
       "4    [is, that, forbidden, for, you, to, tell, the,...   \n",
       "..                                                 ...   \n",
       "295                             [hello, how, s, going]   \n",
       "296                             [i, m, fine, and, you]   \n",
       "297                  [we, have, a, big, snow, outside]   \n",
       "298  [it, may, but, i, have, to, go, for, a, long, ...   \n",
       "299  [i, m, a, bit, affraid, of, bad, roads, cause,...   \n",
       "\n",
       "                                       tokenized_robot  \n",
       "0                           [hi, there, how, are, you]  \n",
       "1                                [here, is, afternoon]  \n",
       "2    [my, name, is, rdany, but, you, can, call, me,...  \n",
       "3    [i, have, many, but, not, enough, to, fully, u...  \n",
       "4    [i, ve, talked, with, 143, users, counting, 72...  \n",
       "..                                                 ...  \n",
       "295                                [hi, how, are, you]  \n",
       "296             [everything, is, fine, on, this, side]  \n",
       "297    [the, kind, that, could, make, you, stay, home]  \n",
       "298                           [put, on, warm, clothes]  \n",
       "299  [i, think, webhooks, are, more, effective, sin...  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine input and target features\n",
    "from itertools import chain\n",
    "\n",
    "total_input = list(chain.from_iterable(df['tokenized_human'].tolist())) + list(chain.from_iterable(df['tokenized_robot'].tolist()))+['<PAD>']\n",
    "total_target = total_input+['<START>', '<END>']\n",
    "input_set = set(total_input)\n",
    "target_set = set(total_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for mapping the words for input features\n",
    "from itertools import chain\n",
    "\n",
    "#input features\n",
    "word_2_int_input = {w:i for i,w in enumerate(input_set)}\n",
    "int_2_word_input = {i:w for w, i in word_2_int_input.items()}\n",
    "\n",
    "#target features\n",
    "word_2_int_target = {w:i for i,w in enumerate(target_set)}\n",
    "int_2_word_target = {i:w for w, i in word_2_int_target.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1214"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_2_int_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1216"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_2_int_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_int_i(sentence):\n",
    "    sequence = [word_2_int_input[word] for word in sentence]\n",
    "    return sequence\n",
    "def map_to_int_t(sentence):\n",
    "    sequence = [word_2_int_target[word] for word in sentence]\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map all word to sequence\n",
    "df['input_sequence'] = df.tokenized_human.apply(map_to_int_i)\n",
    "df['target_sequence'] = df.tokenized_robot.apply(map_to_int_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>robot</th>\n",
       "      <th>pairs</th>\n",
       "      <th>tokenized_human</th>\n",
       "      <th>tokenized_robot</th>\n",
       "      <th>input_sequence</th>\n",
       "      <th>target_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>hi there how are you</td>\n",
       "      <td>(hi, hi there how are you)</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>[hi, there, how, are, you]</td>\n",
       "      <td>[301]</td>\n",
       "      <td>[301, 43, 284, 567, 343]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oh thanks i m fine this is an evening in my ti...</td>\n",
       "      <td>here is afternoon</td>\n",
       "      <td>(oh thanks i m fine this is an evening in my t...</td>\n",
       "      <td>[oh, thanks, i, m, fine, this, is, an, evening...</td>\n",
       "      <td>[here, is, afternoon]</td>\n",
       "      <td>[686, 626, 81, 84, 106, 846, 278, 475, 1075, 6...</td>\n",
       "      <td>[1047, 278, 97]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do you feel today tell me something about ...</td>\n",
       "      <td>my name is rdany but you can call me dany the ...</td>\n",
       "      <td>(how do you feel today tell me something about...</td>\n",
       "      <td>[how, do, you, feel, today, tell, me, somethin...</td>\n",
       "      <td>[my, name, is, rdany, but, you, can, call, me,...</td>\n",
       "      <td>[284, 129, 343, 508, 387, 172, 214, 253, 86, 871]</td>\n",
       "      <td>[578, 20, 278, 396, 720, 343, 704, 376, 214, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many virtual friends have you got</td>\n",
       "      <td>i have many but not enough to fully understand...</td>\n",
       "      <td>(how many virtual friends have you got, i have...</td>\n",
       "      <td>[how, many, virtual, friends, have, you, got]</td>\n",
       "      <td>[i, have, many, but, not, enough, to, fully, u...</td>\n",
       "      <td>[284, 886, 609, 1005, 480, 343, 541]</td>\n",
       "      <td>[81, 480, 886, 720, 922, 192, 125, 1171, 496, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is that forbidden for you to tell the exact nu...</td>\n",
       "      <td>i ve talked with 143 users counting 7294 lines...</td>\n",
       "      <td>(is that forbidden for you to tell the exact n...</td>\n",
       "      <td>[is, that, forbidden, for, you, to, tell, the,...</td>\n",
       "      <td>[i, ve, talked, with, 143, users, counting, 72...</td>\n",
       "      <td>[278, 1079, 700, 818, 343, 125, 172, 242, 698,...</td>\n",
       "      <td>[81, 395, 363, 590, 384, 4, 7, 734, 1037, 54, 75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>hello how s going</td>\n",
       "      <td>hi how are you</td>\n",
       "      <td>(hello how s going, hi how are you)</td>\n",
       "      <td>[hello, how, s, going]</td>\n",
       "      <td>[hi, how, are, you]</td>\n",
       "      <td>[682, 284, 367, 1028]</td>\n",
       "      <td>[301, 284, 567, 343]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>i m fine and you</td>\n",
       "      <td>everything is fine on this side</td>\n",
       "      <td>(i m fine and you, everything is fine on this ...</td>\n",
       "      <td>[i, m, fine, and, you]</td>\n",
       "      <td>[everything, is, fine, on, this, side]</td>\n",
       "      <td>[81, 84, 106, 711, 343]</td>\n",
       "      <td>[400, 278, 106, 427, 846, 954]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>we have a big snow outside</td>\n",
       "      <td>the kind that could make you stay home</td>\n",
       "      <td>(we have a big snow outside, the kind that cou...</td>\n",
       "      <td>[we, have, a, big, snow, outside]</td>\n",
       "      <td>[the, kind, that, could, make, you, stay, home]</td>\n",
       "      <td>[859, 480, 1110, 511, 210, 379]</td>\n",
       "      <td>[242, 723, 1080, 1206, 1002, 343, 1095, 806]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>it may but i have to go for a long way</td>\n",
       "      <td>put on warm clothes</td>\n",
       "      <td>(it may but i have to go for a long way, put o...</td>\n",
       "      <td>[it, may, but, i, have, to, go, for, a, long, ...</td>\n",
       "      <td>[put, on, warm, clothes]</td>\n",
       "      <td>[321, 1143, 720, 81, 480, 125, 420, 818, 1110,...</td>\n",
       "      <td>[802, 427, 664, 1064]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>i m a bit affraid of bad roads cause i m going...</td>\n",
       "      <td>i think webhooks are more effective since it a...</td>\n",
       "      <td>(i m a bit affraid of bad roads cause i m goin...</td>\n",
       "      <td>[i, m, a, bit, affraid, of, bad, roads, cause,...</td>\n",
       "      <td>[i, think, webhooks, are, more, effective, sin...</td>\n",
       "      <td>[81, 84, 1110, 374, 784, 54, 226, 370, 909, 81...</td>\n",
       "      <td>[81, 617, 36, 567, 761, 715, 1055, 321, 428, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 human  \\\n",
       "0                                                   hi   \n",
       "1    oh thanks i m fine this is an evening in my ti...   \n",
       "2    how do you feel today tell me something about ...   \n",
       "3                how many virtual friends have you got   \n",
       "4    is that forbidden for you to tell the exact nu...   \n",
       "..                                                 ...   \n",
       "295                                  hello how s going   \n",
       "296                                   i m fine and you   \n",
       "297                         we have a big snow outside   \n",
       "298             it may but i have to go for a long way   \n",
       "299  i m a bit affraid of bad roads cause i m going...   \n",
       "\n",
       "                                                 robot  \\\n",
       "0                                 hi there how are you   \n",
       "1                                    here is afternoon   \n",
       "2    my name is rdany but you can call me dany the ...   \n",
       "3    i have many but not enough to fully understand...   \n",
       "4    i ve talked with 143 users counting 7294 lines...   \n",
       "..                                                 ...   \n",
       "295                                     hi how are you   \n",
       "296                    everything is fine on this side   \n",
       "297             the kind that could make you stay home   \n",
       "298                                put on warm clothes   \n",
       "299  i think webhooks are more effective since it a...   \n",
       "\n",
       "                                                 pairs  \\\n",
       "0                           (hi, hi there how are you)   \n",
       "1    (oh thanks i m fine this is an evening in my t...   \n",
       "2    (how do you feel today tell me something about...   \n",
       "3    (how many virtual friends have you got, i have...   \n",
       "4    (is that forbidden for you to tell the exact n...   \n",
       "..                                                 ...   \n",
       "295                (hello how s going, hi how are you)   \n",
       "296  (i m fine and you, everything is fine on this ...   \n",
       "297  (we have a big snow outside, the kind that cou...   \n",
       "298  (it may but i have to go for a long way, put o...   \n",
       "299  (i m a bit affraid of bad roads cause i m goin...   \n",
       "\n",
       "                                       tokenized_human  \\\n",
       "0                                                 [hi]   \n",
       "1    [oh, thanks, i, m, fine, this, is, an, evening...   \n",
       "2    [how, do, you, feel, today, tell, me, somethin...   \n",
       "3        [how, many, virtual, friends, have, you, got]   \n",
       "4    [is, that, forbidden, for, you, to, tell, the,...   \n",
       "..                                                 ...   \n",
       "295                             [hello, how, s, going]   \n",
       "296                             [i, m, fine, and, you]   \n",
       "297                  [we, have, a, big, snow, outside]   \n",
       "298  [it, may, but, i, have, to, go, for, a, long, ...   \n",
       "299  [i, m, a, bit, affraid, of, bad, roads, cause,...   \n",
       "\n",
       "                                       tokenized_robot  \\\n",
       "0                           [hi, there, how, are, you]   \n",
       "1                                [here, is, afternoon]   \n",
       "2    [my, name, is, rdany, but, you, can, call, me,...   \n",
       "3    [i, have, many, but, not, enough, to, fully, u...   \n",
       "4    [i, ve, talked, with, 143, users, counting, 72...   \n",
       "..                                                 ...   \n",
       "295                                [hi, how, are, you]   \n",
       "296             [everything, is, fine, on, this, side]   \n",
       "297    [the, kind, that, could, make, you, stay, home]   \n",
       "298                           [put, on, warm, clothes]   \n",
       "299  [i, think, webhooks, are, more, effective, sin...   \n",
       "\n",
       "                                        input_sequence  \\\n",
       "0                                                [301]   \n",
       "1    [686, 626, 81, 84, 106, 846, 278, 475, 1075, 6...   \n",
       "2    [284, 129, 343, 508, 387, 172, 214, 253, 86, 871]   \n",
       "3                 [284, 886, 609, 1005, 480, 343, 541]   \n",
       "4    [278, 1079, 700, 818, 343, 125, 172, 242, 698,...   \n",
       "..                                                 ...   \n",
       "295                              [682, 284, 367, 1028]   \n",
       "296                            [81, 84, 106, 711, 343]   \n",
       "297                    [859, 480, 1110, 511, 210, 379]   \n",
       "298  [321, 1143, 720, 81, 480, 125, 420, 818, 1110,...   \n",
       "299  [81, 84, 1110, 374, 784, 54, 226, 370, 909, 81...   \n",
       "\n",
       "                                       target_sequence  \n",
       "0                             [301, 43, 284, 567, 343]  \n",
       "1                                      [1047, 278, 97]  \n",
       "2    [578, 20, 278, 396, 720, 343, 704, 376, 214, 7...  \n",
       "3    [81, 480, 886, 720, 922, 192, 125, 1171, 496, ...  \n",
       "4    [81, 395, 363, 590, 384, 4, 7, 734, 1037, 54, 75]  \n",
       "..                                                 ...  \n",
       "295                               [301, 284, 567, 343]  \n",
       "296                     [400, 278, 106, 427, 846, 954]  \n",
       "297       [242, 723, 1080, 1206, 1002, 343, 1095, 806]  \n",
       "298                              [802, 427, 664, 1064]  \n",
       "299  [81, 617, 36, 567, 761, 715, 1055, 321, 428, 1...  \n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the length of each sentence\n",
    "\n",
    "df['human_len'] = df.tokenized_human.str.len()\n",
    "df['robot_len'] = df.tokenized_robot.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# find the max length for each sentence to pad in input\n",
    "num_tokens = df['human_len'].tolist() + df['robot_len'].tolist()\n",
    "num_tokens = np.array(num_tokens)\n",
    "max_num = int(np.mean(num_tokens) + 2*np.std(num_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_padded_sequences'] = pad_sequences(df['input_sequence'].tolist(), maxlen=max_num, padding='post', truncating='post').tolist()\n",
    "df['target_padded_sequences'] = pad_sequences(df['target_sequence'].tolist(), maxlen=max_num, padding='post', truncating='post').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>robot</th>\n",
       "      <th>pairs</th>\n",
       "      <th>tokenized_human</th>\n",
       "      <th>tokenized_robot</th>\n",
       "      <th>input_sequence</th>\n",
       "      <th>target_sequence</th>\n",
       "      <th>human_len</th>\n",
       "      <th>robot_len</th>\n",
       "      <th>input_padded_sequences</th>\n",
       "      <th>target_padded_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>hi there how are you</td>\n",
       "      <td>(hi, hi there how are you)</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>[hi, there, how, are, you]</td>\n",
       "      <td>[301]</td>\n",
       "      <td>[301, 43, 284, 567, 343]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[301, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[301, 43, 284, 567, 343, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oh thanks i m fine this is an evening in my ti...</td>\n",
       "      <td>here is afternoon</td>\n",
       "      <td>(oh thanks i m fine this is an evening in my t...</td>\n",
       "      <td>[oh, thanks, i, m, fine, this, is, an, evening...</td>\n",
       "      <td>[here, is, afternoon]</td>\n",
       "      <td>[686, 626, 81, 84, 106, 846, 278, 475, 1075, 6...</td>\n",
       "      <td>[1047, 278, 97]</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>[686, 626, 81, 84, 106, 846, 278, 475, 1075, 6...</td>\n",
       "      <td>[1047, 278, 97, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do you feel today tell me something about ...</td>\n",
       "      <td>my name is rdany but you can call me dany the ...</td>\n",
       "      <td>(how do you feel today tell me something about...</td>\n",
       "      <td>[how, do, you, feel, today, tell, me, somethin...</td>\n",
       "      <td>[my, name, is, rdany, but, you, can, call, me,...</td>\n",
       "      <td>[284, 129, 343, 508, 387, 172, 214, 253, 86, 871]</td>\n",
       "      <td>[578, 20, 278, 396, 720, 343, 704, 376, 214, 7...</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>[284, 129, 343, 508, 387, 172, 214, 253, 86, 8...</td>\n",
       "      <td>[578, 20, 278, 396, 720, 343, 704, 376, 214, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many virtual friends have you got</td>\n",
       "      <td>i have many but not enough to fully understand...</td>\n",
       "      <td>(how many virtual friends have you got, i have...</td>\n",
       "      <td>[how, many, virtual, friends, have, you, got]</td>\n",
       "      <td>[i, have, many, but, not, enough, to, fully, u...</td>\n",
       "      <td>[284, 886, 609, 1005, 480, 343, 541]</td>\n",
       "      <td>[81, 480, 886, 720, 922, 192, 125, 1171, 496, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>[284, 886, 609, 1005, 480, 343, 541, 0, 0, 0, ...</td>\n",
       "      <td>[81, 480, 886, 720, 922, 192, 125, 1171, 496, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is that forbidden for you to tell the exact nu...</td>\n",
       "      <td>i ve talked with 143 users counting 7294 lines...</td>\n",
       "      <td>(is that forbidden for you to tell the exact n...</td>\n",
       "      <td>[is, that, forbidden, for, you, to, tell, the,...</td>\n",
       "      <td>[i, ve, talked, with, 143, users, counting, 72...</td>\n",
       "      <td>[278, 1079, 700, 818, 343, 125, 172, 242, 698,...</td>\n",
       "      <td>[81, 395, 363, 590, 384, 4, 7, 734, 1037, 54, 75]</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>[278, 1079, 700, 818, 343, 125, 172, 242, 698,...</td>\n",
       "      <td>[81, 395, 363, 590, 384, 4, 7, 734, 1037, 54, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>hello how s going</td>\n",
       "      <td>hi how are you</td>\n",
       "      <td>(hello how s going, hi how are you)</td>\n",
       "      <td>[hello, how, s, going]</td>\n",
       "      <td>[hi, how, are, you]</td>\n",
       "      <td>[682, 284, 367, 1028]</td>\n",
       "      <td>[301, 284, 567, 343]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[682, 284, 367, 1028, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[301, 284, 567, 343, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>i m fine and you</td>\n",
       "      <td>everything is fine on this side</td>\n",
       "      <td>(i m fine and you, everything is fine on this ...</td>\n",
       "      <td>[i, m, fine, and, you]</td>\n",
       "      <td>[everything, is, fine, on, this, side]</td>\n",
       "      <td>[81, 84, 106, 711, 343]</td>\n",
       "      <td>[400, 278, 106, 427, 846, 954]</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>[81, 84, 106, 711, 343, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[400, 278, 106, 427, 846, 954, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>we have a big snow outside</td>\n",
       "      <td>the kind that could make you stay home</td>\n",
       "      <td>(we have a big snow outside, the kind that cou...</td>\n",
       "      <td>[we, have, a, big, snow, outside]</td>\n",
       "      <td>[the, kind, that, could, make, you, stay, home]</td>\n",
       "      <td>[859, 480, 1110, 511, 210, 379]</td>\n",
       "      <td>[242, 723, 1080, 1206, 1002, 343, 1095, 806]</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>[859, 480, 1110, 511, 210, 379, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[242, 723, 1080, 1206, 1002, 343, 1095, 806, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>it may but i have to go for a long way</td>\n",
       "      <td>put on warm clothes</td>\n",
       "      <td>(it may but i have to go for a long way, put o...</td>\n",
       "      <td>[it, may, but, i, have, to, go, for, a, long, ...</td>\n",
       "      <td>[put, on, warm, clothes]</td>\n",
       "      <td>[321, 1143, 720, 81, 480, 125, 420, 818, 1110,...</td>\n",
       "      <td>[802, 427, 664, 1064]</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>[321, 1143, 720, 81, 480, 125, 420, 818, 1110,...</td>\n",
       "      <td>[802, 427, 664, 1064, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>i m a bit affraid of bad roads cause i m going...</td>\n",
       "      <td>i think webhooks are more effective since it a...</td>\n",
       "      <td>(i m a bit affraid of bad roads cause i m goin...</td>\n",
       "      <td>[i, m, a, bit, affraid, of, bad, roads, cause,...</td>\n",
       "      <td>[i, think, webhooks, are, more, effective, sin...</td>\n",
       "      <td>[81, 84, 1110, 374, 784, 54, 226, 370, 909, 81...</td>\n",
       "      <td>[81, 617, 36, 567, 761, 715, 1055, 321, 428, 1...</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>[81, 84, 1110, 374, 784, 54, 226, 370, 909, 81...</td>\n",
       "      <td>[81, 617, 36, 567, 761, 715, 1055, 321, 428, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 human  \\\n",
       "0                                                   hi   \n",
       "1    oh thanks i m fine this is an evening in my ti...   \n",
       "2    how do you feel today tell me something about ...   \n",
       "3                how many virtual friends have you got   \n",
       "4    is that forbidden for you to tell the exact nu...   \n",
       "..                                                 ...   \n",
       "295                                  hello how s going   \n",
       "296                                   i m fine and you   \n",
       "297                         we have a big snow outside   \n",
       "298             it may but i have to go for a long way   \n",
       "299  i m a bit affraid of bad roads cause i m going...   \n",
       "\n",
       "                                                 robot  \\\n",
       "0                                 hi there how are you   \n",
       "1                                    here is afternoon   \n",
       "2    my name is rdany but you can call me dany the ...   \n",
       "3    i have many but not enough to fully understand...   \n",
       "4    i ve talked with 143 users counting 7294 lines...   \n",
       "..                                                 ...   \n",
       "295                                     hi how are you   \n",
       "296                    everything is fine on this side   \n",
       "297             the kind that could make you stay home   \n",
       "298                                put on warm clothes   \n",
       "299  i think webhooks are more effective since it a...   \n",
       "\n",
       "                                                 pairs  \\\n",
       "0                           (hi, hi there how are you)   \n",
       "1    (oh thanks i m fine this is an evening in my t...   \n",
       "2    (how do you feel today tell me something about...   \n",
       "3    (how many virtual friends have you got, i have...   \n",
       "4    (is that forbidden for you to tell the exact n...   \n",
       "..                                                 ...   \n",
       "295                (hello how s going, hi how are you)   \n",
       "296  (i m fine and you, everything is fine on this ...   \n",
       "297  (we have a big snow outside, the kind that cou...   \n",
       "298  (it may but i have to go for a long way, put o...   \n",
       "299  (i m a bit affraid of bad roads cause i m goin...   \n",
       "\n",
       "                                       tokenized_human  \\\n",
       "0                                                 [hi]   \n",
       "1    [oh, thanks, i, m, fine, this, is, an, evening...   \n",
       "2    [how, do, you, feel, today, tell, me, somethin...   \n",
       "3        [how, many, virtual, friends, have, you, got]   \n",
       "4    [is, that, forbidden, for, you, to, tell, the,...   \n",
       "..                                                 ...   \n",
       "295                             [hello, how, s, going]   \n",
       "296                             [i, m, fine, and, you]   \n",
       "297                  [we, have, a, big, snow, outside]   \n",
       "298  [it, may, but, i, have, to, go, for, a, long, ...   \n",
       "299  [i, m, a, bit, affraid, of, bad, roads, cause,...   \n",
       "\n",
       "                                       tokenized_robot  \\\n",
       "0                           [hi, there, how, are, you]   \n",
       "1                                [here, is, afternoon]   \n",
       "2    [my, name, is, rdany, but, you, can, call, me,...   \n",
       "3    [i, have, many, but, not, enough, to, fully, u...   \n",
       "4    [i, ve, talked, with, 143, users, counting, 72...   \n",
       "..                                                 ...   \n",
       "295                                [hi, how, are, you]   \n",
       "296             [everything, is, fine, on, this, side]   \n",
       "297    [the, kind, that, could, make, you, stay, home]   \n",
       "298                           [put, on, warm, clothes]   \n",
       "299  [i, think, webhooks, are, more, effective, sin...   \n",
       "\n",
       "                                        input_sequence  \\\n",
       "0                                                [301]   \n",
       "1    [686, 626, 81, 84, 106, 846, 278, 475, 1075, 6...   \n",
       "2    [284, 129, 343, 508, 387, 172, 214, 253, 86, 871]   \n",
       "3                 [284, 886, 609, 1005, 480, 343, 541]   \n",
       "4    [278, 1079, 700, 818, 343, 125, 172, 242, 698,...   \n",
       "..                                                 ...   \n",
       "295                              [682, 284, 367, 1028]   \n",
       "296                            [81, 84, 106, 711, 343]   \n",
       "297                    [859, 480, 1110, 511, 210, 379]   \n",
       "298  [321, 1143, 720, 81, 480, 125, 420, 818, 1110,...   \n",
       "299  [81, 84, 1110, 374, 784, 54, 226, 370, 909, 81...   \n",
       "\n",
       "                                       target_sequence  human_len  robot_len  \\\n",
       "0                             [301, 43, 284, 567, 343]          1          5   \n",
       "1                                      [1047, 278, 97]         12          3   \n",
       "2    [578, 20, 278, 396, 720, 343, 704, 376, 214, 7...         10         21   \n",
       "3    [81, 480, 886, 720, 922, 192, 125, 1171, 496, ...          7         11   \n",
       "4    [81, 395, 363, 590, 384, 4, 7, 734, 1037, 54, 75]         10         11   \n",
       "..                                                 ...        ...        ...   \n",
       "295                               [301, 284, 567, 343]          4          4   \n",
       "296                     [400, 278, 106, 427, 846, 954]          5          6   \n",
       "297       [242, 723, 1080, 1206, 1002, 343, 1095, 806]          6          8   \n",
       "298                              [802, 427, 664, 1064]         11          4   \n",
       "299  [81, 617, 36, 567, 761, 715, 1055, 321, 428, 1...         35         19   \n",
       "\n",
       "                                input_padded_sequences  \\\n",
       "0    [301, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "1    [686, 626, 81, 84, 106, 846, 278, 475, 1075, 6...   \n",
       "2    [284, 129, 343, 508, 387, 172, 214, 253, 86, 8...   \n",
       "3    [284, 886, 609, 1005, 480, 343, 541, 0, 0, 0, ...   \n",
       "4    [278, 1079, 700, 818, 343, 125, 172, 242, 698,...   \n",
       "..                                                 ...   \n",
       "295  [682, 284, 367, 1028, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "296  [81, 84, 106, 711, 343, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "297  [859, 480, 1110, 511, 210, 379, 0, 0, 0, 0, 0,...   \n",
       "298  [321, 1143, 720, 81, 480, 125, 420, 818, 1110,...   \n",
       "299  [81, 84, 1110, 374, 784, 54, 226, 370, 909, 81...   \n",
       "\n",
       "                               target_padded_sequences  \n",
       "0    [301, 43, 284, 567, 343, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [1047, 278, 97, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2    [578, 20, 278, 396, 720, 343, 704, 376, 214, 7...  \n",
       "3    [81, 480, 886, 720, 922, 192, 125, 1171, 496, ...  \n",
       "4    [81, 395, 363, 590, 384, 4, 7, 734, 1037, 54, ...  \n",
       "..                                                 ...  \n",
       "295  [301, 284, 567, 343, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "296  [400, 278, 106, 427, 846, 954, 0, 0, 0, 0, 0, ...  \n",
       "297  [242, 723, 1080, 1206, 1002, 343, 1095, 806, 0...  \n",
       "298  [802, 427, 664, 1064, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "299  [81, 617, 36, 567, 761, 715, 1055, 321, 428, 1...  \n",
       "\n",
       "[300 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pad it first because if we add the <START> and <END> first then after padding these added string might be stripped.\n",
    "\n",
    "target_padded_temp = df['target_padded_sequences'].str[:-1].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 62.5 ms, total: 78.1 ms\n",
      "Wall time: 83.5 ms\n"
     ]
    }
   ],
   "source": [
    "# create 3d for the final d as onehot encoder for decoder output. [data, sentence, word]\n",
    "def generate_onehot(word, word_dict):\n",
    "    z = np.zeros(len(word_dict))\n",
    "    z[word] = 1\n",
    "    return z\n",
    "\n",
    "def get_onehot(series, word_dict):\n",
    "    onehot_l = []\n",
    "    for sentence in series.tolist():\n",
    "        onehot_s = [generate_onehot(word, word_dict) for word in sentence]\n",
    "        onehot_l.append(onehot_s)\n",
    "    return onehot_l\n",
    "\n",
    "%time df['target_padded_onehot'] = get_onehot(df['target_padded_sequences'], word_2_int_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create encoder and decoder input [data, sentence]\n",
    "encoder_input = np.array(df['input_padded_sequences'].tolist())\n",
    "decoder_input = np.array(df['target_padded_sequences'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 22)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 22)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decoder output [data, sentence, word(onehot)]\n",
    "decoder_output = np.array(df['target_padded_onehot'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 22, 1216)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(word_2_int_input)\n",
    "num_decoder_tokens = len(word_2_int_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n",
    "from keras.models import Model, load_model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "INPUT_LENGTH = max_num\n",
    "OUTPUT_LENGTH = 21\n",
    "dict_size = len(word_2_int_target)\n",
    "\n",
    "encoder_input_l = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input_l = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder Tensor(\"lstm/Identity:0\", shape=(None, 22, 512), dtype=float32)\n",
      "encoder_last Tensor(\"strided_slice:0\", shape=(None, 512), dtype=float32)\n",
      "decoder Tensor(\"lstm_1/Identity:0\", shape=(None, 21, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "\n",
    "encoder = Embedding(dict_size, 128, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input_l)\n",
    "encoder = LSTM(512, return_sequences=True, unroll=True)(encoder)\n",
    "encoder_last = encoder[:,-1,:]\n",
    "\n",
    "print('encoder', encoder)\n",
    "print('encoder_last', encoder_last)\n",
    "\n",
    "decoder = Embedding(dict_size, 128, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input_l)\n",
    "decoder = LSTM(512, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
    "\n",
    "print('decoder', decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm/Identity:0' shape=(None, 22, 512) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention Tensor(\"attention_2/Identity:0\", shape=(None, 21, 22), dtype=float32)\n",
      "context Tensor(\"testttt/Identity:0\", shape=(None, 21, 512), dtype=float32)\n",
      "decoder_combined_context Tensor(\"concatenate_2/Identity:0\", shape=(None, 21, 1024), dtype=float32)\n",
      "output Tensor(\"time_distributed_5/Identity:0\", shape=(None, 21, 1216), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, dot, concatenate\n",
    "\n",
    "# Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
    "# Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
    "attention = dot([decoder, encoder], axes=[2, 2], name='test_attention')\n",
    "attention = Activation('softmax', name='attention')(attention)\n",
    "print('attention', attention)\n",
    "\n",
    "context = dot([attention, encoder], axes=[2,1], name='testttt')\n",
    "print('context', context)\n",
    "\n",
    "decoder_combined_context = concatenate([context, decoder])\n",
    "print('decoder_combined_context', decoder_combined_context)\n",
    "\n",
    "# Has another weight + tanh layer as described in equation (5) of the paper\n",
    "output = TimeDistributed(Dense(512, activation=\"tanh\"))(decoder_combined_context)\n",
    "output = TimeDistributed(Dense(dict_size, activation=\"softmax\"))(output)\n",
    "print('output', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 22, 128)      155648      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 21)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 22, 512)      1312768     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 21, 128)      155648      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 512)]        0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 21, 512)      1312768     embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "test_attention (Dot)            (None, 21, 22)       0           lstm_1[0][0]                     \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, 21, 22)       0           test_attention[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "testttt (Dot)                   (None, 21, 512)      0           attention[0][0]                  \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 21, 1024)     0           testttt[0][0]                    \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 21, 512)      524800      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 21, 1216)     623808      time_distributed_4[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 4,085,440\n",
      "Trainable params: 4,085,440\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_input_l, decoder_input_l], outputs=[output])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 425ms/step - loss: 0.0027\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 2s 385ms/step - loss: 0.0027\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 2s 431ms/step - loss: 0.0027\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 2s 424ms/step - loss: 0.0027\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 3s 587ms/step - loss: 0.0027\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 3s 572ms/step - loss: 0.0027\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 2s 488ms/step - loss: 0.0027\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 2s 416ms/step - loss: 0.0027\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 2s 444ms/step - loss: 0.0027\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 4s 764ms/step - loss: 0.0026\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 3s 545ms/step - loss: 0.0026\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 3s 538ms/step - loss: 0.0025\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 2s 439ms/step - loss: 0.0024\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 2s 405ms/step - loss: 0.0024\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 2s 393ms/step - loss: 0.0023\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 2s 405ms/step - loss: 0.0023\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 3s 521ms/step - loss: 0.0023\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 2s 437ms/step - loss: 0.0023\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 2s 441ms/step - loss: 0.0023\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 2s 443ms/step - loss: 0.0022\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 2s 421ms/step - loss: 0.0022\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 2s 394ms/step - loss: 0.0022\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 2s 405ms/step - loss: 0.0022\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 2s 410ms/step - loss: 0.0022\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.0022\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 0.0022\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 2s 359ms/step - loss: 0.0022\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 2s 362ms/step - loss: 0.0022\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 2s 469ms/step - loss: 0.0022\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 2s 396ms/step - loss: 0.0022\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 2s 383ms/step - loss: 0.0022\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 3s 566ms/step - loss: 0.0022\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 3s 561ms/step - loss: 0.0022\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 3s 572ms/step - loss: 0.0021\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 3s 611ms/step - loss: 0.0021\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 3s 672ms/step - loss: 0.0021\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 3s 507ms/step - loss: 0.0021\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 3s 607ms/step - loss: 0.0021\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 2s 462ms/step - loss: 0.0021\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 3s 511ms/step - loss: 0.0021\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 2s 447ms/step - loss: 0.0020\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 2s 435ms/step - loss: 0.0020\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 2s 475ms/step - loss: 0.0020\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 3s 535ms/step - loss: 0.0020\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 2s 446ms/step - loss: 0.0020\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 2s 440ms/step - loss: 0.0019\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 2s 467ms/step - loss: 0.0019\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 2s 385ms/step - loss: 0.0019\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 0.0019\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.0018\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 2s 383ms/step - loss: 0.0018\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 2s 383ms/step - loss: 0.0018\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 2s 498ms/step - loss: 0.0018\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 2s 390ms/step - loss: 0.0017\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 2s 383ms/step - loss: 0.0017\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.0017\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.0017\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.0017\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 2s 427ms/step - loss: 0.0016\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 2s 419ms/step - loss: 0.0016\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 2s 416ms/step - loss: 0.0016\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 2s 452ms/step - loss: 0.0016\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 2s 451ms/step - loss: 0.0015\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 2s 402ms/step - loss: 0.0015\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.0015\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 2s 403ms/step - loss: 0.0015\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 2s 391ms/step - loss: 0.0014\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 2s 419ms/step - loss: 0.0014\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 0.0014\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 2s 390ms/step - loss: 0.0014\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 0.0013\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 2s 378ms/step - loss: 0.0013\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 2s 418ms/step - loss: 0.0013\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.0013\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 2s 393ms/step - loss: 0.0012\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 2s 425ms/step - loss: 0.0012\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 2s 403ms/step - loss: 0.0012\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 2s 446ms/step - loss: 0.0011\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 2s 415ms/step - loss: 0.0011\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 2s 487ms/step - loss: 0.0011\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 3s 545ms/step - loss: 0.0011\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 2s 404ms/step - loss: 0.0010\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 2s 398ms/step - loss: 0.0010\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 9.9320e-04\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 9.6496e-04\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 2s 394ms/step - loss: 9.3767e-04\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 3s 523ms/step - loss: 9.0739e-04\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 2s 488ms/step - loss: 8.7630e-04\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 2s 471ms/step - loss: 8.4891e-04\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 2s 473ms/step - loss: 8.2016e-04\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 2s 490ms/step - loss: 7.8975e-04\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 2s 414ms/step - loss: 7.6896e-04\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 2s 432ms/step - loss: 7.4308e-04\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 2s 421ms/step - loss: 7.1642e-04\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 2s 423ms/step - loss: 6.8636e-04\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 2s 433ms/step - loss: 6.6123e-04\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 2s 419ms/step - loss: 6.3351e-04\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 3s 586ms/step - loss: 6.0784e-04\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 4s 852ms/step - loss: 5.8600e-04\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 3s 646ms/step - loss: 5.6394e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc22bc5c898>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=[decoder_output],\n",
    "          #validation_split=0.05,\n",
    "          batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_attention.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
